## ---------------------------
##
## Script name: streamline_processing.R
##
## Purpose of script: estimating hillslope properties for UK catchments
##
## Author: Piotr Morawiecki
##
## Date Created: 2021-08-20
##
## Copyright (c) Piotr Morawiecki, 2021
## Email: pwm27@bath.ac.uk
##
## ---------------------------
##
## Notes:
##  
##  Script requires two input datasets:
##    - data/NRFA_catchment_boundaries/nrfa_public_ex20200925.shp
##      (more information: https://nrfa.ceh.ac.uk/content/catchment-boundary-and-areas)
##    - output/streamlines/...
##      (generated by streamline_extraction.R script)
##
##  Script uses streamlines generated by streamline_extraction.R script to
##  extract hillslope width and mean elevation gradient along hillslopes
##  for all UK catchments in the NRFA database
##
## ---------------------------

# Set an appropriate working directory (works only when run from RStudio)
# Otherwise replace with setwd('full path to UK-catchment-properties' directory)

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd('..')

# Directory to the input datasets (see section 'Notes' in the header above)

catchment_file <- "data//NRFA_catchment_boundaries//nrfa_public_ex20200925.shp"
streamlines_directory <- "output//streamlines//"

# File to which the results are saved

output_file <- "output//streamline_summary.csv"

## ---------------------------

# Installing required libraries

libraries_required <- c('rgdal', 'rgeos', 'raster', 'sp')
lapply(libraries_required, function(x) {
  if (!require(x, character.only=T)) {install.packages(x);require(x)}
})


# Read input datasets

catchments <- readOGR(dsn = boundaries_file, stringsAsFactors = F)

# Remove ring self-intersections, which may rarely occur in the input datasets

catchments <- gBuffer(catchments, byid=TRUE, width=0)

# List all fires with streamlines in streamlines_directory
# (files are divided into Ordnance Survey National Grid regions)

files <- list.files(streamlines_directory)

# Initialize summary data frame for storing catchment id (id),
# total streamline length (total_distance), total elevation difference
# of all streamlines (total_elevation_diff) and number of streamlines
# in given catchment (n_samples).

summary <- data.frame(id=catchments$STATION, total_distance=0,
                      total_elevation_diff=0, n_samples=0)

# Each region is divided into n_subtiles x n_subtiles subtiles, in order
# to reduce computation time

n_subtiles <- 10

# Streamlines from each file are used to update the summary data

for (i in 1:length(files)) {
  file <- files[i]
  
  # Report current progress
  
  print(paste('Tile processed: ', i, '/', length(files), ' (', file, ')', sep=''))
  
  # Read streamlines from csv file
  
  samples <- read.csv(paste(streamlines_directory, file, sep=''))
  
  # Only streamlines ending in rivers (outlet_type 1 and 2) are analysed.
  # Streamlines ending in sea, local elevation minima or tile boundary
  # are discarded.
  # Note that removing streamlines ending in region boundaries does not have
  # significant impact on estimated values as long as only small fraction of
  # samples is removed in this way.
  
  samples <- samples[samples$outlet_type <= 3, ]
  
  # If no streamlines were selected next file is processed
  
  if (nrow(samples) == 0) next
  
  # Elevation difference is computed for each streamline
  
  samples$dtm_diff <- samples$dtm_point - samples$dtm_outlet
  
  # Convert samples dataframe to SpatialPointDataFrame, in which each streamline
  # is assigned to its starting point
  
  samples_spdf <- SpatialPointsDataFrame(samples[,1:2],
                                         samples[,c('distance', 'dtm_diff')],
                                         proj4string=catchments@proj4string)
  
  # Find tile_extent of the Ordnance Survey National Grid region to which
  # the samples belong. It is found based on first point. Regions have
  # dimensions 100km x 100km (or 1e5m x 1e5m).
  
  xmin <- 1e5 * floor(samples$x[1] / 1e5)
  xmax <- 1e5 * ceiling(samples$x[1] / 1e5)
  ymin <- 1e5 * floor(samples$y[1] / 1e5)
  ymax <- 1e5 * ceiling(samples$y[1] / 1e5)
  tile_extent <- extent(xmin, xmax, ymin, ymax)
  
  # Find catchments, which overlap with the given region
  
  catchments_in_tile <- crop(catchments, tile_extent)
  
  # If no catchments were selected next file is analyzed
  
  if (length(catchments_in_tile) == 0) next
  
  # The region is divided into n_subtiles x n_subtiles subtiles.
  # For each subtile only streamlines belonging to given subtile are overlapped
  # with catchment boundaries, which reduced number of candidates and therefore
  # reduce the computational time required.
  
  for (x in 1:n_subtiles){
    for (y in 1:n_subtiles) {
      
      # Find extent of the subtile
      
      xmin2 <- xmin + (xmax - xmin) * (x-1) / n_subtiles
      ymin2 <- ymin + (ymax - ymin) * (y-1) / n_subtiles
      xmax2 <- xmin + (xmax - xmin) * x / n_subtiles
      ymax2 <- ymin + (ymax - ymin) * y / n_subtiles
      tile_extent <- extent(xmin2, xmax2, ymin2, ymax2)
      
      # Find catchments overlapping with given subtile
      
      catchments_subset <- crop(catchments_in_tile, tile_extent)
      
      # If no catchments overlap proceed to the next subtile
      
      if (length(catchments_subset) == 0) next
      
      # Select streamlines starting from the given subtile.
      
      samples_spdf_subset <- crop(samples_spdf, tile_extent)
      
      # If no streamlines were selected proceed to the next subtile
      
      if (length(samples_spdf_subset) == 0) next
      
      # Streamlines starting from each selected catchment are processed 
      
      for (j in 1:length(catchments_subset)) {
        catchment <- catchments_subset[j,]
        
        # Find row in the summary data frame corresponding to given catchment
        
        row_id <- which(summary$id==catchment$STATION)
        
        # Find and extract streamlines, which overlap with given catchment
        
        samples_subset <- over(samples_spdf_subset, catchment)
        samples_subset <- samples_spdf_subset@data[!is.na(samples_subset$STATION),]
        
        # Calculate total length of streamlines
        
        distance <- sum(samples_subset$distance)
        
        # Calculate total elevation difference
        
        elevation_diff <- sum(samples_subset$dtm_diff)
        
        # Add values calculated above to the summary data frame
        
        summary$total_distance[row_id] <- summary$total_distance[row_id] + distance
        summary$total_elevation_diff[row_id] <- summary$total_elevation_diff[row_id] + elevation_diff
        
        # Increase the number of streamlines starting from given catchment
        
        summary$n_samples[row_id] <- summary$n_samples[row_id] + nrow(samples_subset)
      }
    }
  }
  
  # Write the current version of summary to the output_file.
  # If the script is interrupted one can read this csv file and continue
  # running for loop starting from the last i value.
  
  write.csv(summary, output_file, row.names = FALSE)
}

# Check in which catchments no streamlines were found

no_data <- summary$n_samples==0

# Use obtained values to estimate: 
#   - catchment width as 2 * (mean value of streamline length) 
#   - gradient along hillslope as total elevation difference divided by
#     the total streamline length

summary <- data.frame(id = summary$id,
                      width_B = 2 * summary$total_distance / summary$n_samples,
                      gradient_perpendicular = summary$total_elevation_diff /
                        summary$total_distance)

# For catchments with no streamlines found assign NA to both values

summary[no_data, 2:3] <- NA

# Export the final summary data frame to output_file

write.csv(summary, output_file, row.names = FALSE)
